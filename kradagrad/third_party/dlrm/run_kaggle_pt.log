/home/lukewalters/miniconda3/envs/krad/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/lukewalters/code/dlrm/dlrm_data_pytorch.py:329: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)
  X_int = torch.log(torch.tensor(transposed_data[0], dtype=torch.float) + 1)
world size: 1, current rank: 0, local rank: 0
Using CPU...
Reading pre-processed data=./input/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined train indices...
Randomized indices across days ...
Split data according to indices...
Reading pre-processed data=./input/kaggleAdDisplayChallenge_processed.npz
Sparse fea = 26, Dense fea = 13
Defined test indices...
Randomized indices across days ...
Split data according to indices...
time/loss/accuracy (if enabled):
Traceback (most recent call last):
  File "dlrm_s_pytorch_2ord.py", line 1949, in <module>
    run()
  File "dlrm_s_pytorch_2ord.py", line 1655, in run
    E.backward()
  File "/home/lukewalters/miniconda3/envs/krad/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/lukewalters/miniconda3/envs/krad/lib/python3.8/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: std::bad_alloc
